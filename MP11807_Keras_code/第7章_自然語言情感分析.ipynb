{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\cntk_backend.py:21: UserWarning: CNTK backend warning: GPU is not detected. CNTK's CPU version is not fully optimized,please run with GPU to get better performance.\n",
      "  'CNTK backend warning: GPU is not detected. '\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np \n",
    "from keras.datasets import imdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,    14,    22,    16,    43,   530,   973,  1622,  1385,\n",
       "           65,   458,  4468,    66,  3941,     4,   173,    36,   256,\n",
       "            5,    25,   100,    43,   838,   112,    50,   670, 22665,\n",
       "            9,    35,   480,   284,     5,   150,     4,   172,   112,\n",
       "          167, 21631,   336,   385,    39,     4,   172,  4536,  1111,\n",
       "           17,   546,    38,    13,   447,     4,   192,    50,    16,\n",
       "            6,   147,  2025,    19,    14,    22,     4,  1920,  4613,\n",
       "          469,     4,    22,    71,    87,    12,    16,    43,   530,\n",
       "           38,    76,    15,    13,  1247,     4,    22,    17,   515,\n",
       "           17,    12,    16,   626,    18, 19193,     5,    62,   386,\n",
       "           12,     8,   316,     8,   106,     5,     4,  2223,  5244,\n",
       "           16,   480,    66,  3785,    33,     4,   130,    12,    16,\n",
       "           38,   619,     5,    25,   124,    51,    36,   135,    48,\n",
       "           25,  1415,    33,     6,    22,    12,   215,    28,    77,\n",
       "           52,     5,    14,   407,    16,    82, 10311,     8,     4,\n",
       "          107,   117,  5952,    15,   256,     4, 31050,     7,  3766,\n",
       "            5,   723,    36,    71,    43,   530,   476,    26,   400,\n",
       "          317,    46,     7,     4, 12118,  1029,    13,   104,    88,\n",
       "            4,   381,    15,   297,    98,    32,  2071,    56,    26,\n",
       "          141,     6,   194,  7486,    18,     4,   226,    22,    21,\n",
       "          134,   476,    26,   480,     5,   144,    30,  5535,    18,\n",
       "           51,    36,    28,   224,    92,    25,   104,     4,   226,\n",
       "           65,    16,    38,  1334,    88,    12,    16,   283,     5,\n",
       "           16,  4472,   113,   103,    32,    15,    16,  5345,    19,\n",
       "          178,    32]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_train[0], (1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238.71364"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len = list(map(len, X_train))\n",
    "np.mean(avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhpl+JAkSY0yfEiSpEYZPiRJUqP+PwGudWfL1D7XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x89f5978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.hist(avg_len, bins=range(min(avg_len), max(avg_len) + 50, 50)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Flatten \n",
    "from keras.layers.embeddings import Embedding \n",
    "from keras.preprocessing import sequence \n",
    "import keras \n",
    "import numpy as np \n",
    "from keras.datasets import imdb \n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data() \n",
    "m=max(list(map(len, X_train))+ list(map(len, X_test)))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxword = 400\n",
    "X_train = sequence.pad_sequences(X_train, maxlen = maxword)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen = maxword)\n",
    "vocab_size = np.max([np.max(X_train[i]) for i in range(X_train.shape[0])]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length = maxword))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 64)           5669568   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               12800500  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 18,830,869\n",
      "Trainable params: 18,830,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "  100/25000 [..............................] - ETA: 25:46 - loss: 0.6933 - acc: 0.4900"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function Trainer_train_minibatch> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function Variable___hash__> returned a result with an error set",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <class 'type'> returned a result with an error set",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function Variable___hash__> returned a result with an error set",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ff4665ba7c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\cntk_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m             result = self.trainer.train_minibatch(\n\u001b[0;32m-> 1882\u001b[0;31m                 input_dict, self.trainer_output)\n\u001b[0m\u001b[1;32m   1883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m             \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\cntk\\train\\trainer.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, arguments, outputs, device, is_sweep_end)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 updated = super(Trainer, self).train_minibatch(arguments, is_sweep_end,\n\u001b[0;32m--> 171\u001b[0;31m                     output_map, device)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\cntk\\cntk_py.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3027\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainer_train_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function Trainer_train_minibatch> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 20,batch_size = 100, verbose = 1)\n",
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-41718d2fa6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 400, 64)           5669568   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 400, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 200, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                819264    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,528,001\n",
      "Trainable params: 6,528,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers.embeddings import Embedding \n",
    "from keras.preprocessing import sequence \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length = maxword))\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters = 128, kernel_size = 3, padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 12s - loss: 0.4860 - acc: 0.7189 - val_loss: 0.2693 - val_acc: 0.8892\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.2236 - acc: 0.9138 - val_loss: 0.2645 - val_acc: 0.8916\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.1587 - acc: 0.9424 - val_loss: 0.3100 - val_acc: 0.8764\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.1142 - acc: 0.9597 - val_loss: 0.3152 - val_acc: 0.8799\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0890 - acc: 0.9699 - val_loss: 0.3662 - val_acc: 0.8758\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0641 - acc: 0.9790 - val_loss: 0.4649 - val_acc: 0.8646\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0493 - acc: 0.9840 - val_loss: 0.4959 - val_acc: 0.8565\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0383 - acc: 0.9884 - val_loss: 0.5187 - val_acc: 0.8586\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0267 - acc: 0.9916 - val_loss: 0.7127 - val_acc: 0.8458\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0198 - acc: 0.9939 - val_loss: 1.1308 - val_acc: 0.830004 - ET\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0123 - acc: 0.9963 - val_loss: 0.8761 - val_acc: 0.8527\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0090 - acc: 0.9977 - val_loss: 1.0457 - val_acc: 0.8488\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0072 - acc: 0.9982 - val_loss: 1.1228 - val_acc: 0.8425\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0051 - acc: 0.9993 - val_loss: 1.8203 - val_acc: 0.8360\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0036 - acc: 0.9992 - val_loss: 1.7642 - val_acc: 0.8458acc: \n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0043 - acc: 0.9995 - val_loss: 1.7908 - val_acc: 0.8468\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0021 - acc: 0.9998 - val_loss: 1.9277 - val_acc: 0.8447\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0122 - acc: 0.9987 - val_loss: 1.7697 - val_acc: 0.8481\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0035 - acc: 0.9996 - val_loss: 1.8187 - val_acc: 0.8444\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.0056 - acc: 0.9991 - val_loss: 1.7834 - val_acc: 0.8423\n",
      "24960/25000 [============================>.] - ETA: 0s[1.7833950957139582, 0.84228000000000003]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 20, batch_size = 100)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7833950957139582, 0.84228000000000003]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 400, 64)           5669568   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 400, 128)          98816     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 400, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 400, 64)           49408     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,830,241\n",
      "Trainable params: 5,830,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length = maxword))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 546s - loss: 0.5645 - acc: 0.6731 - val_loss: 0.3635 - val_acc: 0.8475\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 538s - loss: 0.3497 - acc: 0.8590 - val_loss: 0.3994 - val_acc: 0.8179\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 537s - loss: 0.2460 - acc: 0.9079 - val_loss: 0.3249 - val_acc: 0.8659\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 534s - loss: 0.1802 - acc: 0.9357 - val_loss: 0.3177 - val_acc: 0.8644\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 534s - loss: 0.1425 - acc: 0.9505 - val_loss: 0.3417 - val_acc: 0.8508\n",
      "25000/25000 [==============================] - 461s   \n",
      "[0.34172198061943054, 0.85075999999999996]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 5, batch_size = 100)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
